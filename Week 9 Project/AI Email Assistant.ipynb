{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e39021e6",
      "metadata": {
        "id": "e39021e6"
      },
      "source": [
        "Business Context:\n",
        "\n",
        "As a business leader at Orion Tech Solutions, you (â€œAlex Carterâ€) oversee multiple software development and IT infrastructure projects. Your responsibilities include coordinating with stakeholders, managing escalations, and ensuring timely deliveries. With hundreds of emails flooding your inbox daily, manually sorting through them is time-consuming and increases the risk of missing critical updates, client escalations, or project approvals.\n",
        "\n",
        "Objective:\n",
        "The goal of this project is to develop a Generative AI-powered system that:\n",
        "âœ… Summarizes emails into actionable insights using the Yesterbox approach (excluding todayâ€™s emails).\n",
        "âœ… Prioritizes emails based on urgency, sender, and context.\n",
        "âœ… Draft context-aware responses to reduce manual effort.\n",
        "âœ… Evaluate the drafted context-aware responses using LLM-as-a-Judge.\n",
        "Tasks & Workflow\n",
        "Task 1: Generate a Detailed Summary of Yesterdayâ€™s Inbox\n",
        "Task 1A: Executive Dashboard (Top-Level Summary of Yesterdayâ€™s Emails)\n",
        "Sample Output:\n",
        "ğŸ”¹ Total Emails from Yesterday: 100\n",
        "ğŸ”¹ ğŸ›‘ Urgent & High-Priority Emails: 10 (Require Immediate Action Today)\n",
        "ğŸ”¹ âš¡ Deadline-Driven Emails: 8 (Must Be Addressed Today)\n",
        "ğŸ”¹ ğŸ“Œ Routine Updates & Check-ins: 35 (Review & Acknowledge)\n",
        "ğŸ”¹ ğŸ“ Non-Urgent & Informational Emails: 45 (Can Be Deferred or Delegated)\n",
        "ğŸ”¹ ğŸ‰ Personal & Social Emails: 22 (Optional Review)\n",
        "ğŸ”¹ ğŸ—‘ï¸ Spam/Unimportant Emails Filtered Out: 20\n",
        "\n",
        "AI Conclusion:\n",
        "\"You have 18 critical emails from yesterday that require action today. Additionally, there are 35 updates to review at your convenience.\"\n",
        "\n",
        "Task 1B: Analyze Urgent & High-Priority Emails (ğŸ›‘ Must-Do First Today)\n",
        "Focus on emails that require immediate action and impact critical projects or client relationships.\n",
        "\n",
        "Task 1C: Review Deadline-Driven Emails (âš¡ Needs Attention Today)\n",
        "Identify emails tied to important deadlines and ensure timely responses.\n",
        "\n",
        "Task 2: AI-Generated Response Drafts for Critical Email\n",
        "For each Urgent & High-priority email or Deadline-Driven email from yesterday, generate an AI-powered response draft for quick review and editing before sending.\n",
        "\n",
        "NOTE : Critical Emailsare the combination of Urgent & High-Priority Emails + Deadline-Driven Emails\n",
        "\n",
        "Task 3: Validate AI-Generated Results Using the \"LLM as a Judge\" Technique\n",
        "To ensure accuracy and reliability, apply the \"LLM as a Judge\" technique to evaluate:\n",
        "âœ… Relevance: How well does thesummaryaddress the input query or task?\n",
        "âœ… Clarity: How clear and understandable is thesummary?\n",
        "âœ… Actionability: Does thesummaryprovide clear next steps or actionable information?\n",
        "âœ… Strengths: Highlight the key strengths of the summary.\n",
        "âœ… Improvements: Suggest 1-2 areas for improvement.\n",
        "âœ… Overall Justification: Provide a 2-3 line summary evaluation, including key observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "66372fc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66372fc6",
        "outputId": "21915008-e7e1-4f86-c403-8ad205c2ba5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API_KEY loaded from config.json (length 67)\n"
          ]
        }
      ],
      "source": [
        "# Parse JSON content from files\n",
        "import json\n",
        "# Use pathlib for convenient path operations\n",
        "from pathlib import Path\n",
        "\n",
        "# Always load API_KEY from the local `config.json` file; ignore environment variables\n",
        "cfg_path = Path('config.json')\n",
        "API_KEY = None\n",
        "# Check that the config file exists before attempting to read it\n",
        "if cfg_path.exists():\n",
        "    try:\n",
        "        # Open and parse the config file as JSON\n",
        "        with open(cfg_path, 'r', encoding='utf-8') as f:\n",
        "            cfg = json.load(f)\n",
        "        # Look for common key names and take the first non-empty value\n",
        "        API_KEY = cfg.get('API_KEY') or cfg.get('api_key') or cfg.get('openai_api_key')\n",
        "    except Exception:\n",
        "        # If reading or parsing fails, leave API_KEY as None\n",
        "        API_KEY = None\n",
        "else:\n",
        "    # Inform the user if the file is missing\n",
        "    print('config.json not found in the current directory.')\n",
        "\n",
        "# Provide a short confirmation but do not print the secret itself\n",
        "if API_KEY:\n",
        "    print(f'API_KEY loaded from config.json (length {len(API_KEY)})')\n",
        "else:\n",
        "    print('API_KEY not found in config.json. Add it to the file.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "838d4e62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "838d4e62",
        "outputId": "0d478915-8279-4544-b380-fda0786da7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gl-U2Fsd...oxDCQTE2\n"
          ]
        }
      ],
      "source": [
        "# Print a masked form of the API key so the full secret is not exposed\n",
        "# If API_KEY is set, show first 4 and last 4 characters separated by '...'; otherwise print None\n",
        "api_key_val = globals().get('API_KEY')\n",
        "if api_key_val:\n",
        "    print(api_key_val[:8] + '...' + api_key_val[-8:])\n",
        "else:\n",
        "    print(api_key_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b6677750",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6677750",
        "outputId": "7481de35-7bd2-414d-8929-ab995e6d57cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/463.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m463.1/463.1 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai==1.61.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNh7koa0x2op",
        "outputId": "9fbeed86-aea7-49ab-bbd4-dcf9111bc1ac"
      },
      "id": "VNh7koa0x2op",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.61.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Loading the `config.json` file\n",
        "import json, os\n",
        "\n",
        "# Load the JSON file and extract values\n",
        "file_name = 'config.json'\n",
        "with open(file_name, 'r') as file:\n",
        "    config = json.load(file)\n",
        "    os.environ['OPENAI_API_KEY']  = config.get(\"API_KEY\") # Loading the API Key\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = config.get(\"OPENAI_API_BASE\") # Loading the API Base Url"
      ],
      "metadata": {
        "id": "-nlVsYc_zS8T"
      },
      "id": "-nlVsYc_zS8T",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt-4o-mini\""
      ],
      "metadata": {
        "id": "Ke6yF3EW0mFo"
      },
      "id": "Ke6yF3EW0mFo",
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}