{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e39021e6",
      "metadata": {
        "id": "e39021e6"
      },
      "source": [
        "Business Context:\n",
        "\n",
        "As a business leader at Orion Tech Solutions, you (‚ÄúAlex Carter‚Äù) oversee multiple software development and IT infrastructure projects. Your responsibilities include coordinating with stakeholders, managing escalations, and ensuring timely deliveries. With hundreds of emails flooding your inbox daily, manually sorting through them is time-consuming and increases the risk of missing critical updates, client escalations, or project approvals.\n",
        "\n",
        "Objective:\n",
        "The goal of this project is to develop a Generative AI-powered system that:\n",
        "‚úÖ Summarizes emails into actionable insights using the Yesterbox approach (excluding today‚Äôs emails).\n",
        "‚úÖ Prioritizes emails based on urgency, sender, and context.\n",
        "‚úÖ Draft context-aware responses to reduce manual effort.\n",
        "‚úÖ Evaluate the drafted context-aware responses using LLM-as-a-Judge.\n",
        "Tasks & Workflow\n",
        "Task 1: Generate a Detailed Summary of Yesterday‚Äôs Inbox\n",
        "Task 1A: Executive Dashboard (Top-Level Summary of Yesterday‚Äôs Emails)\n",
        "Sample Output:\n",
        "üîπ Total Emails from Yesterday: 100\n",
        "üîπ üõë Urgent & High-Priority Emails: 10 (Require Immediate Action Today)\n",
        "üîπ ‚ö° Deadline-Driven Emails: 8 (Must Be Addressed Today)\n",
        "üîπ üìå Routine Updates & Check-ins: 35 (Review & Acknowledge)\n",
        "üîπ üìé Non-Urgent & Informational Emails: 45 (Can Be Deferred or Delegated)\n",
        "üîπ üéâ Personal & Social Emails: 22 (Optional Review)\n",
        "üîπ üóëÔ∏è Spam/Unimportant Emails Filtered Out: 20\n",
        "\n",
        "AI Conclusion:\n",
        "\"You have 18 critical emails from yesterday that require action today. Additionally, there are 35 updates to review at your convenience.\"\n",
        "\n",
        "Task 1B: Analyze Urgent & High-Priority Emails (üõë Must-Do First Today)\n",
        "Focus on emails that require immediate action and impact critical projects or client relationships.\n",
        "\n",
        "Task 1C: Review Deadline-Driven Emails (‚ö° Needs Attention Today)\n",
        "Identify emails tied to important deadlines and ensure timely responses.\n",
        "\n",
        "Task 2: AI-Generated Response Drafts for Critical Email\n",
        "For each Urgent & High-priority email or Deadline-Driven email from yesterday, generate an AI-powered response draft for quick review and editing before sending.\n",
        "\n",
        "NOTE : Critical Emailsare the combination of Urgent & High-Priority Emails + Deadline-Driven Emails\n",
        "\n",
        "Task 3: Validate AI-Generated Results Using the \"LLM as a Judge\" Technique\n",
        "To ensure accuracy and reliability, apply the \"LLM as a Judge\" technique to evaluate:\n",
        "‚úÖ Relevance: How well does thesummaryaddress the input query or task?\n",
        "‚úÖ Clarity: How clear and understandable is thesummary?\n",
        "‚úÖ Actionability: Does thesummaryprovide clear next steps or actionable information?\n",
        "‚úÖ Strengths: Highlight the key strengths of the summary.\n",
        "‚úÖ Improvements: Suggest 1-2 areas for improvement.\n",
        "‚úÖ Overall Justification: Provide a 2-3 line summary evaluation, including key observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "66372fc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66372fc6",
        "outputId": "21915008-e7e1-4f86-c403-8ad205c2ba5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API_KEY loaded from config.json (length 67)\n"
          ]
        }
      ],
      "source": [
        "# Parse JSON content from files\n",
        "import json\n",
        "# Use pathlib for convenient path operations\n",
        "from pathlib import Path\n",
        "\n",
        "# Always load API_KEY from the local `config.json` file; ignore environment variables\n",
        "cfg_path = Path('config.json')\n",
        "API_KEY = None\n",
        "# Check that the config file exists before attempting to read it\n",
        "if cfg_path.exists():\n",
        "    try:\n",
        "        # Open and parse the config file as JSON\n",
        "        with open(cfg_path, 'r', encoding='utf-8') as f:\n",
        "            cfg = json.load(f)\n",
        "        # Look for common key names and take the first non-empty value\n",
        "        API_KEY = cfg.get('API_KEY') or cfg.get('api_key') or cfg.get('openai_api_key')\n",
        "    except Exception:\n",
        "        # If reading or parsing fails, leave API_KEY as None\n",
        "        API_KEY = None\n",
        "else:\n",
        "    # Inform the user if the file is missing\n",
        "    print('config.json not found in the current directory.')\n",
        "\n",
        "# Provide a short confirmation but do not print the secret itself\n",
        "if API_KEY:\n",
        "    print(f'API_KEY loaded from config.json (length {len(API_KEY)})')\n",
        "else:\n",
        "    print('API_KEY not found in config.json. Add it to the file.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "838d4e62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "838d4e62",
        "outputId": "0d478915-8279-4544-b380-fda0786da7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gl-U2Fsd...oxDCQTE2\n"
          ]
        }
      ],
      "source": [
        "# Print a masked form of the API key so the full secret is not exposed\n",
        "# If API_KEY is set, show first 4 and last 4 characters separated by '...'; otherwise print None\n",
        "api_key_val = globals().get('API_KEY')\n",
        "if api_key_val:\n",
        "    print(api_key_val[:8] + '...' + api_key_val[-8:])\n",
        "else:\n",
        "    print(api_key_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b6677750",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6677750",
        "outputId": "7481de35-7bd2-414d-8929-ab995e6d57cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/463.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m463.1/463.1 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai==1.61.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNh7koa0x2op",
        "outputId": "9fbeed86-aea7-49ab-bbd4-dcf9111bc1ac"
      },
      "id": "VNh7koa0x2op",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.61.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Loading the `config.json` file\n",
        "import json, os\n",
        "\n",
        "# Load the JSON file and extract values\n",
        "file_name = 'config.json'\n",
        "with open(file_name, 'r') as file:\n",
        "    config = json.load(file)\n",
        "    os.environ['OPENAI_API_KEY']  = config.get(\"API_KEY\") # Loading the API Key\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = config.get(\"OPENAI_API_BASE\") # Loading the API Base Url"
      ],
      "metadata": {
        "id": "-nlVsYc_zS8T"
      },
      "id": "-nlVsYc_zS8T",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt-4o-mini\""
      ],
      "metadata": {
        "id": "Ke6yF3EW0mFo"
      },
      "id": "Ke6yF3EW0mFo",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "Dd7mN9S-1Lz8"
      },
      "id": "Dd7mN9S-1Lz8",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title LLM function\n",
        "# @markdown Once the API details are filled, the notebook will automatically load the configuration, and learners can generate model outputs using the llm() function.\n",
        "\n",
        "\n",
        "def llm(system_prompt, user_prompt):\n",
        "  try:\n",
        "      # Craft the messages to pass to chat.completions.create\n",
        "      prompt = [\n",
        "          {'role':'system', 'content': system_prompt},\n",
        "          {'role': 'user', 'content': user_prompt}\n",
        "      ]\n",
        "\n",
        "      response = client.chat.completions.create(\n",
        "          model=model_name,\n",
        "          messages=prompt,\n",
        "          temperature=0\n",
        "      )\n",
        "\n",
        "      return response.choices[0].message.content.strip()\n",
        "\n",
        "  except Exception as e:\n",
        "      prediction = f'Sorry, I encountered the following error: \\n {e}'\n",
        "      print(prediction)"
      ],
      "metadata": {
        "id": "FPanTZF41UAC"
      },
      "id": "FPanTZF41UAC",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 1: Load the Dataset\n",
        "# Data Loading\n",
        "\n",
        "import pandas as pd\n",
        "# Use the raw GitHub URL for the CSV file\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/linufx2208-sketch/JHU_Learnings/main/Week%209%20Project/Alex_emails_march_04.csv\", index_col=\"email_id\", encoding='latin-1')      #Add the data file location\n",
        "df"
      ],
      "metadata": {
        "id": "517utX3w1v7L"
      },
      "id": "517utX3w1v7L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 2: Apply Yesterbox Filtering\n",
        "# @markdown The Yesterbox approach involves processing emails from the previous day first before tackling today's emails.\n",
        "\n",
        "# @markdown For this dataset, consider today's date as 4th March 2025.\n",
        "\n",
        "# @markdown We filter the dataset to only include emails received on 3rd March 2025 (yesterday)\n",
        "# (Yesterbox Approach)(Today: 4 march)\n",
        "\n",
        "\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "yesterday_date = pd.to_datetime(\"3/3/2025\").strftime('%m/%d/%Y')\n",
        "\n",
        "df['date_received'] = pd.to_datetime(df['date_received']).dt.strftime('%m/%d/%Y')\n",
        "\n",
        "yesterday_emails = df[df['date_received'] == yesterday_date].reset_index(drop=True)\n",
        "print(f\"Filtered Emails Count: {len(yesterday_emails)}\")\n"
      ],
      "metadata": {
        "id": "PGH_ZLoW-jlE",
        "outputId": "e63a6a30-8814-479c-f113-69fef481e720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PGH_ZLoW-jlE",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Emails Count: 51\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}